[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Kevin Miller",
    "section": "",
    "text": "About Me\nI am an entry-level data analyst with a diverse skill set and expertise cultivated through graduate-level studies in neuroscience and data analytics.\nMy most recent master’s in data analytics has further solidified my foundation in statistical expertise, particularly with advanced machine learning models. I am actively enhancing my versatility as a data analyst by applying these techniques—including Clustering, Deep Learning, Dimensionality Reduction, and Natural Language Processing (NLP)—to answer novel research questions.\nThis approach, combined with my background in academic research, enables me to approach data analytics with a methodical, research-oriented mindset, focusing on deriving novel insights.\n\n\nEducation\n\nMS Data Analytics\nWestern Governors University\n\n\nMA Psychology\nUniversity of Nebraska-Lincoln\n\n\nBS Psychology\nEmporia State University"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projects",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nCapstone Report\n\n\nChi-Square and Random Forest Regression with Data Science Jobs Dataset\n\n\n\n\nPython\n\n\nDescriptive Analysis\n\n\nRandom Forest\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2024\n\n\nKevin B. Miller\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About Me",
    "section": "",
    "text": "I am an entry-level data analyst with a diverse skill set and expertise cultivated through graduate-level studies in neuroscience and data analytics.\nMy most recent master’s in data analytics has further solidified my foundation in statistical expertise, particularly with advanced machine learning models. I am actively enhancing my versatility as a data analyst by applying these techniques—including Clustering, Deep Learning, Dimensionality Reduction, and Natural Language Processing (NLP)—to answer novel research questions.\nThis approach, combined with my background in academic research, enables me to approach data analytics with a methodical, research-oriented mindset, focusing on deriving novel insights."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\nMS Data Analytics\nWestern Governors University\n\n\nMA Psychology\nUniversity of Nebraska-Lincoln\n\n\nBS Psychology\nEmporia State University"
  },
  {
    "objectID": "posts/capstone_report/code/capstone_report.html",
    "href": "posts/capstone_report/code/capstone_report.html",
    "title": "Capstone Report",
    "section": "",
    "text": "This work represents a finalized Capstone Report for my Master’s of Science in Data Analytics from Western Governors University (WGU). To comply with WGU’s academic integrity guidelines, the present document was not submitted as part of my Capstone. Rather, this report represents an extension of the project that showcases my work without making my submitted materials publicly available."
  },
  {
    "objectID": "posts/capstone_report/code/capstone_report.html#abstract",
    "href": "posts/capstone_report/code/capstone_report.html#abstract",
    "title": "Capstone Report",
    "section": "Abstract",
    "text": "Abstract\nThe growth of data science as a field has produced simultaneous increases in role diversification. The present study further characterized differences between job roles by examining whether experience levels varied between data science job categories. This study focused on a subset of publicly available data comprising data science employees working full-time in the U.S. (N = 12,389). A Chi-Square Test of Independence with subsequent post hoc tests analyzed the association between experience level and job category. A Random Forest Regression model was used to predict salaries from experience level, job category, and work setting. Experience level composition varied between job categories (X2 = 1003.54, p &lt; .001), with each job category differing from all others (p-range: p &lt; .001 - p = .001). Residual analysis revealed two experience level-job category intersections with substantially greater observed counts than expected: executive employees in leadership roles and entry-level employees in data analysis roles. Employees in these experience levels were otherwise underrepresented, whereas senior employees comprised a sizable portion of each job category. The Random Forest Regression model explained roughly 25% of the variance in employee salary. Salary estimates were higher for employees in machine learning or AI-related roles or senior positions, and lower for employees in data analysis roles. This study further characterized differences between data science roles, most notably for experience levels typically found in each. These findings have implications for the accessibility of these roles, particularly for entry-level employees, who may have fewer attainable job roles."
  },
  {
    "objectID": "posts/capstone_report/code/capstone_report.html#introduction-and-research-question",
    "href": "posts/capstone_report/code/capstone_report.html#introduction-and-research-question",
    "title": "Capstone Report",
    "section": "1: Introduction and Research Question",
    "text": "1: Introduction and Research Question\nAfter being heralded as the “sexiest job of the 21st century” (Davenport & Patil, 2012), the data scientist role met these lofty expectations (Davenport & Patil, 2022), and is expected to continue growing through 2032 (U.S. Bureau of Labor Statistics, 2024). The responsibilities of this role grew simultaneously, requiring more specialized data science roles be created to focus on a portion of the data science process (Davenport & Patil, 2022). Examples of these expanded roles include the data engineer and data analyst (Rosidi, 2023), with the former focusing on the quality and accessibility of data and the latter focusing on analysis and reporting of data. Yet with seemingly more job roles, demand, and resources to learn data science than ever (Davenport & Patil, 2022), many of those attempting to break into the field find themselves frustrated and disillusioned (Selvaraj, 2022).\nThis mismatch between the expectations and experiences of data science hopefuls underscores the need to characterize the skills and experiences necessary to succeed in a data science role. Greater transparency surrounding these factors would demystify the field as a whole and provide a better road map for employment-ready data science professionals. Using an open dataset on data science jobs from Kaggle (Zangari, n.d.), this study sought to discern whether there was a categorical association between experience level and job category in data science jobs. Following a statistically significant Chi-Square Test of Independence omnibus test, the experience level composition of individual job categories would be compared using the same Chi-Square test. An additional Random Forest Regression (RFR) model was used to estimate salary from experience level, job category, and work setting.\n\n1.1: Research Question and Hypotheses\nDoes experience level composition vary between data science job categories?\nNull Hypothesis (H0): The proportion of employees at each experience level does not vary between job categories in the dataset.\nAlternative Hypothesis (HA): The proportion of employees at each experience level varies between job categories in the dataset."
  },
  {
    "objectID": "posts/capstone_report/code/capstone_report.html#data-collection",
    "href": "posts/capstone_report/code/capstone_report.html#data-collection",
    "title": "Capstone Report",
    "section": "2: Data Collection",
    "text": "2: Data Collection\nThis data used in this study is publicly available on Kaggle (Zangari, n.d.). The data was originally collected and compiled by ai-jobs.net (2024), and features responses from data science professionals and employers. The main adaptation made in the Kaggle version was the addition of the job_categories feature, which collapsed 149 unique job titles into ten general categories. This was highly advantageous for the scope of this study, as it would be difficult to compare and interpret differences between 149 different job titles.\n\n# import useful libraries\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom IPython.display import Markdown, display\n\n\n# read in csv file as dataframe\njob_df = pd.read_csv('../data/jobs_in_data_2024.csv')\n\n\n2.1: Exploratory Data Analysis\nThe dataset contained 14,199 records without any missing values for any columns. The chronological range of responses began in 2020, with some responses as recent as this year (i.e., 2024). Since some features pertained to similar constructs (e.g., job_title and job_category), it was important to gauge the usability of features and levels therein. For instance, some features had a large number of levels (e.g., job_title, employee_residence, and company_location), which can be difficult to analyze. Additionally, features like employment_type, employee_residence, and company_location exhibited considerable categorical imbalances, with the vast majority of responses belonging to one category.\n\n# get initial info for df\njob_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14199 entries, 0 to 14198\nData columns (total 12 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   work_year           14199 non-null  int64 \n 1   experience_level    14199 non-null  object\n 2   employment_type     14199 non-null  object\n 3   job_title           14199 non-null  object\n 4   salary              14199 non-null  int64 \n 5   salary_currency     14199 non-null  object\n 6   salary_in_usd       14199 non-null  int64 \n 7   employee_residence  14199 non-null  object\n 8   work_setting        14199 non-null  object\n 9   company_location    14199 non-null  object\n 10  company_size        14199 non-null  object\n 11  job_category        14199 non-null  object\ndtypes: int64(3), object(9)\nmemory usage: 1.3+ MB\n\n\n\n# get number of unique values for each variable \nfor column in job_df.columns:\n    print(column, len(job_df[column].value_counts()))\n\nwork_year 5\nexperience_level 4\nemployment_type 4\njob_title 149\nsalary 2229\nsalary_currency 12\nsalary_in_usd 2578\nemployee_residence 86\nwork_setting 3\ncompany_location 74\ncompany_size 3\njob_category 10\n\n\n\n# get value counts for each object variable\nfor column in job_df.columns:\n    if job_df[column].dtype == object:\n        print(job_df[column].value_counts(), \"\\n\")\n\nexperience_level\nSenior         9381\nMid-level      3339\nEntry-level    1063\nExecutive       416\nName: count, dtype: int64 \n\nemployment_type\nFull-time    14139\nContract        26\nPart-time       22\nFreelance       12\nName: count, dtype: int64 \n\njob_title\nData Engineer                    3059\nData Scientist                   2910\nData Analyst                     2120\nMachine Learning Engineer        1488\nResearch Scientist                454\n                                 ... \nData Analytics Associate            1\nAnalytics Engineering Manager       1\nSales Data Analyst                  1\nAWS Data Architect                  1\nConsultant Data Engineer            1\nName: count, Length: 149, dtype: int64 \n\nsalary_currency\nUSD    13146\nGBP      538\nEUR      422\nCAD       51\nAUD       12\nPLN        7\nCHF        6\nSGD        6\nBRL        4\nTRY        3\nDKK        3\nNZD        1\nName: count, dtype: int64 \n\nemployee_residence\nUnited States     12418\nUnited Kingdom      616\nCanada              371\nSpain               131\nGermany              90\n                  ...  \nAndorra               1\nUganda                1\nOman                  1\nQatar                 1\nLuxembourg            1\nName: count, Length: 86, dtype: int64 \n\nwork_setting\nIn-person    9413\nRemote       4573\nHybrid        213\nName: count, dtype: int64 \n\ncompany_location\nUnited States           12465\nUnited Kingdom            623\nCanada                    373\nSpain                     127\nGermany                    96\n                        ...  \nAndorra                     1\nQatar                       1\nMauritius                   1\nGibraltar                   1\nMoldova, Republic of        1\nName: count, Length: 74, dtype: int64 \n\ncompany_size\nM    13112\nL      919\nS      168\nName: count, dtype: int64 \n\njob_category\nData Science and Research         4675\nData Engineering                  3157\nData Analysis                     2204\nMachine Learning and AI           2148\nLeadership and Management          791\nBI and Visualization               600\nData Architecture and Modeling     419\nData Management and Strategy       115\nData Quality and Operations         79\nCloud and Database                  11\nName: count, dtype: int64 \n\n\n\n\n# show distribution for salary_in_usd\nsns.histplot(job_df['salary_in_usd'])\nplt.show()\n\n# show distribution for salary\nsns.histplot(job_df['salary'])\nplt.show()"
  },
  {
    "objectID": "posts/capstone_report/code/capstone_report.html#data-extraction-and-preparation",
    "href": "posts/capstone_report/code/capstone_report.html#data-extraction-and-preparation",
    "title": "Capstone Report",
    "section": "3: Data Extraction and Preparation",
    "text": "3: Data Extraction and Preparation\nDue to categorical imbalances shown in the previous section, the dataset was filtered to only include employees residing in the U.S. (employee_residence), working for a U.S.-based company (company_location), and working full-time (employment_type). While this reduced the potential generalizability of findings, it was important to recognize that the data was already biased towards these groups, and any attempt to generalize beyond that would be undermined to begin with. Filtering for these categories reduced the number of observations to 12,389, which constituted less than 13% data loss. Features work_setting and company_size were not filtered to remedy categorical imbalances, as each feature contained only three levels, and the degree of the imbalance was less concerning. Potential outliers and skewness in salary_in_usd were not treated, as Random Forest models are robust to outliers and extreme values (Deori, 2023), and high salaries were potentially noteworthy in the RFR model.\nOf the twelve original features, only four were kept for analyses: experience_level, salary_in_usd, work_setting, and job_category. After filtering for employment_type, employee_residence, company_location, these three features were excluded on the basis that each was no longer a variable (i.e., each only had one value). The feature job_category was used place of job_title, as the former had far lower cardinality (i.e., ten unique value vs. 149), making it far easier to incorporate in analyses. Filtering by country meant salary_in_usd could be used in place of salary and salary_currency, as conversions would not be necessary. Features work_year and company_size would have been nice to add to the salary estimation Random Forest Regression model, but both had sub-optimal distributions and level structures to analyze.\n\n# create separate df for just US employees working for US companies\nus_job_df = job_df.loc[(job_df['employee_residence'] == 'United States') & \n                       (job_df['company_location'] == 'United States')]\n\n\n# filter df to only include full-time employees\nus_job_df = us_job_df.loc[us_job_df['employment_type'] == 'Full-time']\nprint(us_job_df['employment_type'].value_counts())\n\nemployment_type\nFull-time    12389\nName: count, dtype: int64\n\n\n\n# reset index to align with observations\nus_job_df.reset_index(inplace=True, drop=True)\n\n\n# keep only relevant variables\nrefined_us_job_df = us_job_df[['experience_level', 'salary_in_usd', 'work_setting',\n                               'job_category']]\n\n\n3.A: Chi-Square Model Preparation\nInitial cross tabulations characterized the expected frequencies of experience_level and job_category before running the Chi-Square model (see Table 1). The a-priori criteria defined in this project’s proposal was that any job categories with fewer than five expected counts in any cell would be combined with other job categories meeting this criteria. Such low expected counts would be abnormally low for a dataset of this size, and collapsing categories can serve as a sound solution without incurring data loss (Bewick et al., 2003). The job categories Cloud and Database, Data Management and Strategy, and Data Quality and Operations all had fewer than five expected counts for at least one experience level, leading these to be combined into one category (see Table 1 (a)). Rather than labeling this category as “Other,” these categories all pertained to Data Management, which served as a more descriptive label (see Table 1 (b)). The final cross tabulation to be used in the Chi-Square analysis was saved as trans_refined_ct.\n\n# create crosstab for experience_level and job_category, with margins\nimport statsmodels.api as sm\n#pd.set_option('display.float_format', lambda x: '{0:.2f}' % x)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.precision', 3)\n\n#pd.set_option('display.precision', 2)\ncross_tab = pd.crosstab(refined_us_job_df['experience_level'], \n                        refined_us_job_df['job_category'], \n                        margins=True)\n\n\n# obtain expected values for crosstab\nexpected_table = sm.stats.Table(cross_tab)\n#expected_table.fittedvalues.round(2).T\n\n\n# create copy before transforming levels\nct_us_job_df = refined_us_job_df.copy(deep=True)\n\n\n# convert 3 levels to Data Management\nct_us_job_df.replace({'job_category': \n                      {'Cloud and Database': 'Data Management', \n                       'Data Management and Strategy': 'Data Management', \n                       'Data Quality and Operations': 'Data Management'}}, \n                      inplace=True)\n\n\n# define and output new contingency table\nrefined_ct = pd.crosstab(ct_us_job_df['experience_level'], \n                         ct_us_job_df['job_category'])\nrefined_expected_table = sm.stats.Table(refined_ct)\n\n\n# create expected table with margins\nmarginal_ct = pd.crosstab(ct_us_job_df['experience_level'], \n                          ct_us_job_df['job_category'], margins=True)\nmarginal_expected_table = sm.stats.Table(marginal_ct)\n\n\n# create rounded, transposed versions of tables\nct_exp_md = expected_table.fittedvalues.round(2).T\nct_ref_exp_md = marginal_expected_table.fittedvalues.round(2).T\n\n# display markdown versions of tables\ndisplay(Markdown(ct_exp_md.to_markdown()))\ndisplay(Markdown(ct_ref_exp_md.to_markdown()))\n\n\nTable 1: Original and refined expected counts contingency tables.\n\n\n\n\n(a) Original (ten job categories)\n\n\n\n\n\n\n\n\n\n\njob_category\nEntry-level\nExecutive\nMid-level\nSenior\nAll\n\n\n\n\nBI and Visualization\n33.39\n15.52\n115.16\n365.96\n529.97\n\n\nCloud and Database\n0.72\n0.34\n2.5\n7.94\n11.5\n\n\nData Analysis\n119.19\n55.39\n411.09\n1306.42\n1891.9\n\n\nData Architecture and Modeling\n23.77\n11.05\n81.97\n260.49\n377.23\n\n\nData Engineering\n175.44\n81.54\n605.12\n1923.03\n2784.86\n\n\nData Management and Strategy\n6.13\n2.85\n21.13\n67.15\n97.25\n\n\nData Quality and Operations\n4.17\n1.94\n14.39\n45.75\n66.25\n\n\nData Science and Research\n260.55\n121.1\n898.66\n2855.9\n4135.79\n\n\nLeadership and Management\n43.15\n20.06\n148.84\n472.99\n684.97\n\n\nMachine Learning and AI\n114.02\n52.99\n393.27\n1249.8\n1809.91\n\n\nAll\n780.46\n362.73\n2691.86\n8554.57\n12388.4\n\n\n\n\n\n\n\n\n(b) Refined (eight job categories)\n\n\n\n\n\n\n\n\n\n\njob_category\nEntry-level\nExecutive\nMid-level\nSenior\nAll\n\n\n\n\nBI and Visualization\n33.38\n15.5\n115.16\n365.97\n529.99\n\n\nData Analysis\n119.15\n55.32\n411.1\n1306.46\n1891.96\n\n\nData Architecture and Modeling\n23.76\n11.03\n81.97\n260.5\n377.24\n\n\nData Engineering\n175.39\n81.43\n605.14\n1923.09\n2784.94\n\n\nData Management\n10.97\n5.09\n37.86\n120.32\n174.25\n\n\nData Science and Research\n260.48\n120.93\n898.69\n2855.98\n4135.92\n\n\nLeadership and Management\n43.14\n20.03\n148.84\n473\n684.99\n\n\nMachine Learning and AI\n113.99\n52.92\n393.29\n1249.84\n1809.96\n\n\nAll\n780.23\n362.24\n2691.95\n8554.83\n12388.8\n\n\n\n\n\n\n\n\n# save final contingency table for use in analyses\ntrans_refined_ct = refined_ct.T\n\n\n\n3.B: Random Forest Regressor Model Preparation\n\n3.B.1: Encoding Section\nSince scikit-learn’s RFR implementation can only accept numeric features, predictors for the RFR model (experience_level, work_setting, and job_category) were transformed using a one-hot encoding (OHE) method. While added sparsity from OHE features can reduce model efficiency and performance (Ravi, 2022), other encoding methods that do not increase sparsity (e.g., integer or ordinal encoding) can create unintended relationships between feature levels (Brownlee, 2020b). Such ordered relationships would have been defensible for features experience_level and work_setting, but these were also encoded using an OHE method for consistency with the job_category feature. By using the ColumnTransformer() function to apply OHE, the target variable, salary_in_usd, was left unaffected, and the output was automatically transformed into a pandas dataframe. This resulted in seventeen OHE features, corresponding to the levels of experience_level (n = 4), work_setting (n = 3), and job_category (n = 10).\n\n# import libraries necessary for transformation\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\n\n# get list of categorical columns to transform\ncat_df = refined_us_job_df[['experience_level', 'work_setting', 'job_category']]\ncat_cols = list(cat_df.keys())\nprint(cat_cols)\n\n['experience_level', 'work_setting', 'job_category']\n\n\n\n# define transformer with non-sparse output\ncat_transformer = OneHotEncoder(sparse_output=False)\n\n\n# apply transformer to cat_cols, while passing over salary_in_usd\nct = ColumnTransformer([('cat', cat_transformer, cat_cols)], remainder='passthrough')\n\n\n# set output to pandas df and fit to data\nct.set_output(transform='pandas')\ndc_us_job_df = ct.fit_transform(refined_us_job_df)\ndc_us_job_df.columns\n\nIndex(['cat__experience_level_Entry-level', 'cat__experience_level_Executive',\n       'cat__experience_level_Mid-level', 'cat__experience_level_Senior',\n       'cat__work_setting_Hybrid', 'cat__work_setting_In-person',\n       'cat__work_setting_Remote', 'cat__job_category_BI and Visualization',\n       'cat__job_category_Cloud and Database',\n       'cat__job_category_Data Analysis',\n       'cat__job_category_Data Architecture and Modeling',\n       'cat__job_category_Data Engineering',\n       'cat__job_category_Data Management and Strategy',\n       'cat__job_category_Data Quality and Operations',\n       'cat__job_category_Data Science and Research',\n       'cat__job_category_Leadership and Management',\n       'cat__job_category_Machine Learning and AI',\n       'remainder__salary_in_usd'],\n      dtype='object')\n\n\n\n\n3.B.2: Feature Selection\nOnce the features were all in a numeric format, scikit-learn’s SelectKBest() discerned which variables were significantly associated with salary (see Table 2 for a summary). The scoring function used was f_regression(), due to the target feature being continuous. Three features were not significantly associated with salary_in_usd at the p &lt; .05 level (cat__work_setting_Hybrid, cat__job_category_Data Architecture and Modeling, cat__job_category_Cloud and Database). These features were dropped from subsequent analyses, leaving a total of fourteen features.\n\n# import libraries for feature selection\nfrom sklearn.feature_selection import SelectKBest, f_regression\n\n\n# create X and y arrays for feature selection and beyond\ny = dc_us_job_df['remainder__salary_in_usd']\nX = dc_us_job_df.drop(['remainder__salary_in_usd'], axis=1)\nprint(f'''X shape: {X.shape}, y shape: {y.shape}''')\n\nX shape: (12389, 17), y shape: (12389,)\n\n\n\n# create SelectKBest instance using f_regression on all features\nfeature_rank = SelectKBest(score_func=f_regression, k='all')\n# fit to data\nfeature_rank.fit(X, y=y)\n\nSelectKBest(k='all', score_func=&lt;function f_regression at 0x314232fc0&gt;)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SelectKBestSelectKBest(k='all', score_func=&lt;function f_regression at 0x314232fc0&gt;)\n\n\n\n# create df to show features, F-scores, and p-values\nfeature_df = pd.DataFrame({'Feature': X.columns, \n                           'F-score': feature_rank.scores_.round(2), \n                           'P-value': feature_rank.pvalues_.round(3)})\n# sort lowest p-values first \nfeature_df = feature_df.sort_values(by='P-value', ascending=True)\ndisplay(Markdown(feature_df.to_markdown()))\n\n\n\nTable 2: Feature importances ranked by significance.\n\n\n\n\n\n\n\n\n\nFeature\nF-score\nP-value\n\n\n\n\n0\ncat__experience_level_Entry-level\n643.87\n0\n\n\n14\ncat__job_category_Data Science and Research\n321.51\n0\n\n\n13\ncat__job_category_Data Quality and Operations\n53.27\n0\n\n\n12\ncat__job_category_Data Management and Strategy\n97.05\n0\n\n\n9\ncat__job_category_Data Analysis\n1323\n0\n\n\n15\ncat__job_category_Leadership and Management\n23.38\n0\n\n\n7\ncat__job_category_BI and Visualization\n89.74\n0\n\n\n16\ncat__job_category_Machine Learning and AI\n791.71\n0\n\n\n5\ncat__work_setting_In-person\n23.33\n0\n\n\n3\ncat__experience_level_Senior\n838.27\n0\n\n\n2\ncat__experience_level_Mid-level\n509.32\n0\n\n\n1\ncat__experience_level_Executive\n169.43\n0\n\n\n6\ncat__work_setting_Remote\n21.73\n0\n\n\n11\ncat__job_category_Data Engineering\n10.23\n0.001\n\n\n4\ncat__work_setting_Hybrid\n2.18\n0.14\n\n\n10\ncat__job_category_Data Architecture and Modeling\n1.64\n0.2\n\n\n8\ncat__job_category_Cloud and Database\n0.58\n0.446\n\n\n\n\n\n\n\n# drop non-significant p-values from features\nX = X.drop(['cat__work_setting_Hybrid', \n            'cat__job_category_Data Architecture and Modeling', \n            'cat__job_category_Cloud and Database'], axis=1)\n\n\n\n3.B.3: Train-Test-Split\nFollowing the conventions of machine learning best practices, the data for the RFR model was split into training and testing sets, with a ratio of 70:30 in favor of the training set. This ensures the RFR model can generalize beyond the data it trained on (i.e., to the testing set), since this resembles the type of predictive modeling paradigm wherein the predicted values are not available (Brownlee, 2020a). This 70:30 split resulted in training sets with 8,672 observations and testing sets with 3,717 observations.\n\n# create train and test arrays from X and y with 80% train\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, \n                                                    random_state=21)\n\n\n# output dimensions of train and test sets \nprint(f'''X_train shape: {X_train.shape}, X_test shape: {X_test.shape}, \n      y_train shape: {y_train.shape}, y_test shape: {y_test.shape}''')\n\nX_train shape: (8672, 14), X_test shape: (3717, 14), \n      y_train shape: (8672,), y_test shape: (3717,)"
  },
  {
    "objectID": "posts/capstone_report/code/capstone_report.html#analysis",
    "href": "posts/capstone_report/code/capstone_report.html#analysis",
    "title": "Capstone Report",
    "section": "4: Analysis",
    "text": "4: Analysis\n\n4.A: Chi-Square Model\n\n4.A.1: Omnibus\nThe omnibus-level Chi-Square Test of Independence was statistically significant (X2 = 1003.54, p &lt; .001). Thus, the null hypothesis was rejected, as the experience level composition of employees varied between job categories. This necessitated further post hoc testing to compare experience level composition between job categories.\n\n# output omnibus Chi-Square result\nfrom scipy.stats import chi2_contingency\nresult = chi2_contingency(trans_refined_ct)\nprint(f'''Statistic: {result.statistic}, P-value: {result.pvalue}''')\n\nStatistic: 1003.5413047409224, P-value: 4.926315041672239e-199\n\n\n\n\n4.A.2: Post Hoc Tests\nThe post hoc tests were completed using code adapted from Neuhof (2018), as this helped streamline the process for the 28 job category comparisons. Instead of printing these comparisons as in the original code, converting to and printing a dataframe yielded a cleaner output (see Table 3). Given the large dataset at hand, a more stringent Bonferroni correction was used to correct for alpha inflation (Jafari & Ansari-Pour, 2019), as this method multiples the statistical significance by the number of comparisons made. Despite this, all 28 comparisons were statistically significant after the Bonferroni correction (Bonferroni-corrected p-range: p &lt; .001 - p = .001). Focusing instead on the magnitude of the effect size in terms of X2, the three strongest effects resulted from comparisons with Data Analysis (compared to Data Engineer, Machine Learning and AI, and Data Science and Research, respectively). The visualizations in the following suggest that Data Analysis had more Entry-level employees relative to the comparison categories.\n\n# code adapted from Neuhof (2018)\nfrom itertools import combinations\n\n# gathering all combinations for post-hoc chi2\nall_combinations = list(combinations(trans_refined_ct.index, 2))\nchi2_vals = []\np_vals = []\nfor comb in all_combinations:\n    # subset df into a dataframe containing only the pair \"comb\"\n    new_df = trans_refined_ct[(trans_refined_ct.index == comb[0]) | \n                              (trans_refined_ct.index == comb[1])]\n    # running chi2 test\n    chi2, p, dof, ex = chi2_contingency(new_df, correction=True)\n    chi2_vals.append(chi2)\n    p_vals.append(p)\n\n\n# create dataframe with combinations, effect sizes, and p-vals\nchi2_df = pd.DataFrame({'Combination': all_combinations, \n                        'Statistic': chi2_vals, \n                        'p': p_vals})\n# create Bonferroni-corrected p-values by multiplying by number of tests\nchi2_df['p-Bonf'] = (chi2_df['p'] * 28).round(3)\nchi2_df['Statistic'] = chi2_df['Statistic'].round(2)\nchi2_df['p'] = chi2_df['p'].round(3)\n# sort df by effect size \nchi2_df = chi2_df[['Combination', 'Statistic', 'p', 'p-Bonf']].sort_values(\nby='Statistic', ascending=False)\n# print as markdown\ndisplay(Markdown(chi2_df.to_markdown()))\n\n\n\nTable 3: Job category comparisons ranked by Chi-Square statistic.\n\n\n\n\n\n\n\n\n\n\nCombination\nStatistic\np\np-Bonf\n\n\n\n\n8\n(‘Data Analysis’, ‘Data Engineering’)\n340.85\n0\n0\n\n\n12\n(‘Data Analysis’, ‘Machine Learning and AI’)\n325.68\n0\n0\n\n\n10\n(‘Data Analysis’, ‘Data Science and Research’)\n297.49\n0\n0\n\n\n11\n(‘Data Analysis’, ‘Leadership and Management’)\n199.27\n0\n0\n\n\n27\n(‘Leadership and Management’, ‘Machine Learning and AI’)\n170.07\n0\n0\n\n\n7\n(‘Data Analysis’, ‘Data Architecture and Modeling’)\n156.55\n0\n0\n\n\n14\n(‘Data Architecture and Modeling’, ‘Data Management’)\n149.71\n0\n0\n\n\n24\n(‘Data Management’, ‘Machine Learning and AI’)\n140.46\n0\n0\n\n\n25\n(‘Data Science and Research’, ‘Leadership and Management’)\n127.48\n0\n0\n\n\n16\n(‘Data Architecture and Modeling’, ‘Leadership and Management’)\n122.45\n0\n0\n\n\n1\n(‘BI and Visualization’, ‘Data Architecture and Modeling’)\n96.26\n0\n0\n\n\n18\n(‘Data Engineering’, ‘Data Management’)\n86.38\n0\n0\n\n\n6\n(‘BI and Visualization’, ‘Machine Learning and AI’)\n84.62\n0\n0\n\n\n21\n(‘Data Engineering’, ‘Machine Learning and AI’)\n75.22\n0\n0\n\n\n22\n(‘Data Management’, ‘Data Science and Research’)\n73.34\n0\n0\n\n\n13\n(‘Data Architecture and Modeling’, ‘Data Engineering’)\n70.68\n0\n0\n\n\n15\n(‘Data Architecture and Modeling’, ‘Data Science and Research’)\n63.27\n0\n0\n\n\n23\n(‘Data Management’, ‘Leadership and Management’)\n57.52\n0\n0\n\n\n26\n(‘Data Science and Research’, ‘Machine Learning and AI’)\n56.39\n0\n0\n\n\n0\n(‘BI and Visualization’, ‘Data Analysis’)\n53\n0\n0\n\n\n20\n(‘Data Engineering’, ‘Leadership and Management’)\n50.03\n0\n0\n\n\n19\n(‘Data Engineering’, ‘Data Science and Research’)\n39.92\n0\n0\n\n\n9\n(‘Data Analysis’, ‘Data Management’)\n30.91\n0\n0\n\n\n5\n(‘BI and Visualization’, ‘Leadership and Management’)\n29.99\n0\n0\n\n\n2\n(‘BI and Visualization’, ‘Data Engineering’)\n27\n0\n0\n\n\n3\n(‘BI and Visualization’, ‘Data Management’)\n25.48\n0\n0\n\n\n4\n(‘BI and Visualization’, ‘Data Science and Research’)\n22.98\n0\n0.001\n\n\n17\n(‘Data Architecture and Modeling’, ‘Machine Learning and AI’)\n22.92\n0\n0.001\n\n\n\n\n\n\n\n\n4.A.3: Chi-Square Visualizations\nThe contingency cross tabulation tables are shown below for the observed (see Table 4 (a)) and expected counts (see Table 4 (b)). Rather than focusing on these individually, a residual table was created to show observed counts deviated from the expected counts for each cell (see Table 4 (c)). Residuals were calculated as the difference between the observed and expected counts divided by the expected values ((O - E) / E), which yields both the direction and magnitude of difference between the two. The accompanying heatmap (see Figure 1) shows where counts were greater than expected in red (e.g., Entry-level and Data Analysis or Executive and Leadership and Management) and fewer than expected in blue (e.g., Entry-level and Data Architecture and Modeling or Executive and Data Management). The bivariate plots compare the experience level composition across job categories, using the proportion (Figure 2 (a)) and count of employees (Figure 2 (b)) with each experience level. Figure 2 (a) re-iterates the findings that Data Analysis for Entry-level employees and Leadership and Management for Executive employees were relative peaks among less-represented experience levels. Conversely, Senior employees comprised a sizable portion of every job category, and the clear majority of a few (e.g., Data Architecture and Modeling, Machine Learning and AI). Figure 2 (b) uses number of employees for the y-axis variable, which takes into account size differences between job categories. This again depicts the relative commonality of Senior employees, as three of four largest categories (Data Science and Research, Data Engineering, and Machine Learning and AI) contained a substantial number of Senior employees.\n\n# set order of Chi-Square variables\n# set experience order\nexperience_order = pd.CategoricalDtype(['Entry-level', 'Mid-level', 'Senior', \n                                        'Executive'], ordered=True)\nct_us_job_df.experience_level = ct_us_job_df.experience_level.astype(experience_order)\n# set job category order to alphabetical\ncategory_order = pd.CategoricalDtype(['BI and Visualization', 'Data Analysis', \n                                      'Data Architecture and Modeling', \n                                      'Data Engineering', 'Data Management', \n                                      'Data Science and Research', \n                                      'Leadership and Management', \n                                      'Machine Learning and AI'], ordered=True)\nct_us_job_df.job_category = ct_us_job_df.job_category.astype(category_order)\n\n\n# create crosstabs without margins\nobserved_ct = pd.crosstab(ct_us_job_df['experience_level'],\n                          ct_us_job_df['job_category'], margins=False)\nexpected_ct = sm.stats.Table(observed_ct)\n\n\n# convert cts to dfs and transpose\nexpected_df = pd.DataFrame(expected_ct.fittedvalues).T\nobserved_df = pd.DataFrame(observed_ct).T\n\n\n# run transformations to create residuals \nresid_div_ct_df = observed_df.subtract(expected_df)\nresid_div_ct_df = resid_div_ct_df.divide(expected_df)\n\n\n# round all dfs for better outputting\nexpected_df = expected_df.round(2)\nobserved_df = observed_df.round(2)\nresid_div_ct_df = resid_div_ct_df.round(2)\n\n\n# display tables in markdown format\ndisplay(Markdown(observed_df.to_markdown()))\ndisplay(Markdown(expected_df.to_markdown(index=False)))\ndisplay(Markdown(resid_div_ct_df.to_markdown()))\n\n\nTable 4: Contingency Tables\n\n\n\n\n(a) Observed counts.\n\n\n\n\n\n\n\n\n\njob_category\nEntry-level\nMid-level\nSenior\nExecutive\n\n\n\n\nBI and Visualization\n37\n150\n325\n18\n\n\nData Analysis\n347\n450\n1075\n20\n\n\nData Architecture and Modeling\n0\n34\n339\n4\n\n\nData Engineering\n95\n623\n1937\n130\n\n\nData Management\n22\n74\n78\n0\n\n\nData Science and Research\n216\n866\n2954\n100\n\n\nLeadership and Management\n16\n216\n393\n60\n\n\nMachine Learning and AI\n47\n279\n1454\n30\n\n\n\n\n\n\n(b) Expected counts.\n\n\nEntry-level\nMid-level\nSenior\nExecutive\n\n\n\n\n33.39\n115.15\n365.95\n15.51\n\n\n119.19\n411.08\n1306.38\n55.36\n\n\n23.78\n82.02\n260.65\n11.04\n\n\n175.44\n605.1\n1922.98\n81.48\n\n\n10.99\n37.91\n120.49\n5.11\n\n\n260.54\n898.64\n2855.81\n121.01\n\n\n43.15\n148.83\n472.98\n20.04\n\n\n114.02\n393.26\n1249.76\n52.96\n\n\n\n\n\n\n\n\n(c) Residual counts.\n\n\n\n\n\n\n\n\n\njob_category\nEntry-level\nMid-level\nSenior\nExecutive\n\n\n\n\nBI and Visualization\n0.11\n0.3\n-0.11\n0.16\n\n\nData Analysis\n1.91\n0.09\n-0.18\n-0.64\n\n\nData Architecture and Modeling\n-1\n-0.59\n0.3\n-0.64\n\n\nData Engineering\n-0.46\n0.03\n0.01\n0.6\n\n\nData Management\n1\n0.95\n-0.35\n-1\n\n\nData Science and Research\n-0.17\n-0.04\n0.03\n-0.17\n\n\nLeadership and Management\n-0.63\n0.45\n-0.17\n1.99\n\n\nMachine Learning and AI\n-0.59\n-0.29\n0.16\n-0.43\n\n\n\n\n\n\n\n\n# show residuals using heatmap using blue and red colors, centering on 0\nresid_heatmap = sns.heatmap(resid_div_ct_df, annot=True, cmap='coolwarm', center=0)\nresid_heatmap.set(xlabel='Experience Level', ylabel='Job Category')\nplt.show()\n\n\n\n\nFigure 1: Chi-Square residual heatmap. Positive values denote greater observed counts than expected in red. Negative values denoting fewer observed counts than expected are shown in blue.\n\n\n\n\n\n# reset experience_order to show experience vertically\nexperience_order = pd.CategoricalDtype(['Executive', 'Senior', 'Mid-level', \n                                        'Entry-level'], ordered=True)\nct_us_job_df.experience_level = ct_us_job_df.experience_level.astype(experience_order)\n\n\n# show bivariate plots for experience level and job category proportions and counts\nwith sns.color_palette('colorblind'):\n    prop_hist = sns.histplot(data=ct_us_job_df, x='job_category', \n                             hue='experience_level', stat='proportion', \n                             multiple='fill', discrete=True)\n    prop_hist.set_xticklabels(['BI/Viz', 'DA', 'DArc/Modeling', 'DE', 'DM', \n                               'DS/Research', 'Leadership', 'ML/AI'], rotation=45)\n    prop_hist.set(xlabel='Job Category', ylabel='Proportion of Employees')#, \n                  #title='Experience Level Composition by Job Category')\n    prop_hist.get_legend().set_title('Experience Level')\n    plt.show()\n\n    count_hist = sns.histplot(data=ct_us_job_df, x='job_category', \n                              hue='experience_level', multiple='stack')\n    count_hist.set_xticklabels(['BI/Viz', 'DA', 'DArc/Modeling', 'DE', 'DM', \n                                'DS/Research', 'Leadership', 'ML/AI'], rotation=45)\n    count_hist.set(xlabel='Job Category', ylabel='Number of Employees')\n    count_hist.get_legend().set_title('Experience Level')\n    plt.show()\n\n\n\n\n\n\n\n(a) Proportion of job category with each experience level.\n\n\n\n\n\n\n\n(b) Number of employees with experience level across job categories.\n\n\n\n\nFigure 2: Experience level and job category composition. Abbreviations: BI/Viz: BI and Visualization; DA: Data Analysis; DArc/Modeling: Data Architecture and Modeling; DE: Data Engineering; DM: Data Management; DS/Research: Data Science and Research; Leadership: Leadership and Management; ML/AI: Machine Learning and AI.\n\n\n\n\n\n\n4.B: Random Forest Regressor Model\n\n4.B.1: Grid Search for RFR\nTo create a more robust RFR model, hyperparameters of interest were tuned using GridSearchCV to evaluate hyperparameter combinations with the training data. The parameter grid was constructed using guidelines from Ellis (2022), specifying values in a reasonable range for n_estimators, max_features, and one parameter to limit tree depth (e.g., max_depth). With root-mean-squared error (RMSE) as the a-priori error metric for the RFR model, the scoring metric for the grid search object was set to neg_root_mean_squared_error. This grid search object was supplied a default RFR model and the parameter grid, and subsequently fit to the X_train and y_train datasets for five cross-validation folds. The resulting best parameters were max_depth = 8, max_features = ‘sqrt’, and n_estimators = 50, which were used with the models in the next section (see section 4.B.2: Train and Test Model Performance).\n\n# import libraries necessary for hyperparameter tuning\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\n\n\n# define MSE for later use\nMSE = metrics.mean_squared_error\n\n\n# instantiate baseline model\nrf_model = RandomForestRegressor(random_state=21)\n\n\n# construct parameter grid to for hyperparameters of interest\nparam_grid = {'n_estimators': [50, 100, 200, 400], \n              'max_depth': [2, 4, 8, None],\n              'max_features': ['sqrt', 'log2', None]\n              }\n\n\n# fit GridSearchCV to rf_model with param_grid and scoring as negative RMSE\ngs_rf = GridSearchCV(rf_model, param_grid=param_grid, \n                     scoring='neg_root_mean_squared_error', cv=5)\n\n\n# fit grid search object to data\ngs_rf.fit(X_train, y_train)\n\nGridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=21),\n             param_grid={'max_depth': [2, 4, 8, None],\n                         'max_features': ['sqrt', 'log2', None],\n                         'n_estimators': [50, 100, 200, 400]},\n             scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=21),\n             param_grid={'max_depth': [2, 4, 8, None],\n                         'max_features': ['sqrt', 'log2', None],\n                         'n_estimators': [50, 100, 200, 400]},\n             scoring='neg_root_mean_squared_error')estimator: RandomForestRegressorRandomForestRegressor(random_state=21)RandomForestRegressorRandomForestRegressor(random_state=21)\n\n\n\n# output best parameters from grid search\nprint(gs_rf.best_params_)\n\n{'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 50}\n\n\n\n\n4.B.2: Train and Test Model Performance\nThe training model performance was evaluated from the grid search object directly, from which the RMSE and R2 values were extracted. The final RFR model was created with tuned hyperparameters and fit to X_train and y_train, and subsequently used to predict y_test using X_test. Model performance was comparable in the training (RMSE = 53,050.72, R2 = .2448) and testing models (RMSE = 54,352.70, R2 = .2525). The testing model performance indicates that the features explained roughly 25% of the variance in salary, and the salary estimates were off by roughly $54,000 on average. The convergence between the error and explained variance metrics between the training and testing models suggest the model was not overfit to the training data.\n\n# get RMSE and R2 from best grid search model (training)\ngrid_rmse = (gs_rf.best_score_ * -1)\nprint('Training RMSE: ', round(grid_rmse, 2))\ngrid_predict = gs_rf.predict(X_train)\nprint('Training R-Squared: ', round(metrics.r2_score(y_true=y_train, \n      y_pred=grid_predict), 4))\n\nTraining RMSE:  53050.72\nTraining R-Squared:  0.2448\n\n\n\n# define final RFR model with best parameters\nrfr_model = RandomForestRegressor(max_depth=8, \n                                  max_features='sqrt', \n                                  n_estimators=50, \n                                  random_state=21)\n\n\n# fit final model to X_train and y_train\nrfr_model.fit(X_train, y_train)\n\nRandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=50,\n                      random_state=21)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressorRandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=50,\n                      random_state=21)\n\n\n\n# using that RFR model, predict y_test using X_test\ny_test_pred = rfr_model.predict(X_test)\n\n\n# get RMSE and R2 values from test model\ntest_RMSE = np.sqrt(MSE(y_test, y_test_pred))\ntest_R2 = metrics.r2_score(y_test, y_test_pred)\nprint('Test RMSE: ', round(test_RMSE, 2))\nprint('Test R-Squared: ', round(test_R2, 4))\n\nTest RMSE:  54352.7\nTest R-Squared:  0.2525\n\n\n\n\n4.B.3: Feature Importances and Tree Diagram\nFeature importances were extracted from the RFR model, converted to a dataframe, and sorted in descending order (see Table 5). The values ranged from .008 to .286, with all features explaining at least some variance, and the magnitude gradually decreasing with each subsequent feature (see Figure 3). The top three features included the Data Analysis job category (.286), Machine Learning and AI job category (.162), and Senior experience level (.136). Unsurprisingly, these were the first three features used to split the data in the RFR tree diagram (see Figure 4), which underscores each feature’s importance to estimating salary. The code for this diagram was adapted from a TensorFlow tutorial (Visualizing TensorFlow Decision Forest Trees with Dtreeviz, 2024), and this figure makes it easy to interpret how the absence or presence of an experience level, job category, or work setting altered the RFR model’s salary estimate. With the depth of the model, however, only the first three levels of the diagram could be displayed before the clarity of the figure diminished.\n\n# create df for features and corresponding importances \nfeature_df = pd.DataFrame({'Feature': X.columns, \n                           'Importance': rfr_model.feature_importances_})\n# sort the values with higher importances first\nfeature_df['Importance'] = feature_df['Importance'].round(3)\nfeature_df = feature_df.sort_values(by='Importance', ascending=False)\n# display sorted df as markdown\ndisplay(Markdown(feature_df.to_markdown()))\n\n\n\nTable 5: Sorted feature importances in Random Forest model.\n\n\n\nFeature\nImportance\n\n\n\n\n7\ncat__job_category_Data Analysis\n0.286\n\n\n13\ncat__job_category_Machine Learning and AI\n0.162\n\n\n3\ncat__experience_level_Senior\n0.136\n\n\n0\ncat__experience_level_Entry-level\n0.082\n\n\n2\ncat__experience_level_Mid-level\n0.082\n\n\n11\ncat__job_category_Data Science and Research\n0.079\n\n\n1\ncat__experience_level_Executive\n0.056\n\n\n6\ncat__job_category_BI and Visualization\n0.028\n\n\n8\ncat__job_category_Data Engineering\n0.022\n\n\n9\ncat__job_category_Data Management and Strategy\n0.02\n\n\n5\ncat__work_setting_Remote\n0.015\n\n\n4\ncat__work_setting_In-person\n0.013\n\n\n12\ncat__job_category_Leadership and Management\n0.012\n\n\n10\ncat__job_category_Data Quality and Operations\n0.008\n\n\n\n\n\n\n\n# create split version of encoded feature names\nfeature_df['sep_Variable'] = feature_df['Feature'].str.split(r'_', regex=True,\n                                                              expand=False)\n# take last portion of the split for cleaner feature names\nfeature_df['short_Variable'] = feature_df['sep_Variable'].str[-1]\n\n\n# visualize feature importances in descending order \nwith sns.color_palette('colorblind'):\n    feature_bar = sns.barplot(data=feature_df, x='Importance', y='short_Variable')\n    feature_bar.set(xlabel='Impurity-based Feature Importance', ylabel='Feature')\n    plt.show()\n\n\n\n\nFigure 3: Feature importances in Random Forest model.\n\n\n\n\n\n# code adapted from Visualizing TensorFlow Decision Trees with Dtreeviz (2024)\nimport dtreeviz\n\n# create dtreeviz model from RFR model\nviz_rfr_model = dtreeviz.model(rfr_model.estimators_[0], X, y, \n                               tree_index=3,\n                               feature_names=feature_df['short_Variable'], \n                               target_name='Salary')\n# only show first three levels of depth for sake of clarity\nviz_rfr_model.view(depth_range_to_display=[0,2], scale=1.2)\n\n\n\n\nFigure 4: Tree diagram from Random Forest model. Only the first three levels are shown to preserve figure clarity."
  },
  {
    "objectID": "posts/capstone_report/code/capstone_report.html#data-summary-and-implications",
    "href": "posts/capstone_report/code/capstone_report.html#data-summary-and-implications",
    "title": "Capstone Report",
    "section": "5: Data Summary and Implications",
    "text": "5: Data Summary and Implications\nThe results of the Chi-Square Test of Independence were statistically significant (see section 4.A.1: Omnibus), thus rejecting the null hypothesis that the experience level of employees did not vary between job categories (see section 1.1: Research Question and Hypotheses). With regards to this study’s research question, experience level composition varied between job categories, which suggests that some data science positions are typically held by more experienced employees than others. One limitation of using a Chi-Square test with this data was that it may have been overpowered, as all job category post hoc comparisons exhibited significant differences, even following a Bonferroni correction (see section 4.A.2: Post Hoc Tests). This shifted the focus from statistical significance of the comparisons to the magnitude of the effects, as quantified by the X2 values and the residuals, (see section 4.A.3: Chi-Square Visualizations for visualizations). Both metrics converged to suggest the Data Analysis job category was unique in its distribution of experience levels, which featured the highest proportion of entry-level employees.\nWhile the RFR model was not intended to test or evaluate hypotheses, the final model performed relatively well considering the challenges of the data (see section 4.B.2: Train and Test Model Performance). The features accounted for more than one-quarter of the variance in salary, which is impressive considering the fourteen encoded features originated from only three features. One limitation described in section 3.B.1: Encoding Section was the use of sparse categorical data in the RFR model, which has been shown to diminish performance or interpretability in some Random Forest models (Ravi, 2022). Interestingly, the RFR testing model performance (R2) outperformed the training model slightly (.2525 compared to .2448), which was unexpected. This can likely be attributed to the idiosyncratic, random nature of the train-test-split function (see section 3.B.3: Train-Test-Split), which may have given the testing set a slightly “easier” dataset to predict. Since the training model had a better RMSE value than the testing set (53,050.72 compared to 54,352.70), the training model still estimated salary better than the testing set, and the unexpected R2 comparison is likely not concerning.\nThe results of this study may be helpful for characterizing the field of data science at large. Firstly, the analyses using the data at hand suggest that entry-level positions are relatively rare in data science. This may lend credence to the idea that fewer entry-level positions are available in the field (Selvaraj, 2022), although, further studies should investigate this claim. The relative spike of entry-level employees in the data analysis job category supports multiple resources cited here (Selvaraj, 2022; Simmons, 2023). Each of these suggested a data analyst position may be an intermediate step for an entry-level employee to become a data scientist, and the results of this study suggest this may be plausible. Lastly, the results of the RFR model suggest some experience levels, job categories, and work settings tend to earn a higher salary than others. Notably, employees in the Data Analysis job category tended to earn less, whereas Senior employees, or employees in the Machine Learning and AI job category tended to earn more.\nFour considerations for future studies examining the field of data science are recommended following analyses here. One technical improvement would be to use an RFR model with non-sparse categorical features, to see if this potentially improves model performance or interpretability. An alternative to the scikit-learn workflow is the Distributed Random Forest model from H2O.ai (2024), which can incorporate nominal feature structures without requiring transformations. Concerning the association between experience level and job category, obtaining each employee’s entry-level position to data science would help create more holistic, trajectory-based snapshots of data science careers. This could also disentangle whether some roles with higher proportions of entry-level employees (e.g., Data Analysis) could feasibly serve as an intermediate step to another position (Selvaraj, 2022; Simmons, 2023). Concerning the RFR model, including more features that might be associated with data science salaries (e.g., education level, years of employment, or geographic location) could improve salary estimates and model performance. Lastly, acquiring more stratified data with respect to employee status, employee residence, and company location would help generalize analyses beyond full-time employees, residing in the U.S., and working for a U.S.-based company."
  },
  {
    "objectID": "posts/capstone_report/code/capstone_report.html#references",
    "href": "posts/capstone_report/code/capstone_report.html#references",
    "title": "Capstone Report",
    "section": "References",
    "text": "References\n\n\nai-jobs.net. (2024). Get a full dataset of global AI, ML, Data Salaries. https://ai-jobs.net/salaries/download/\n\n\nBewick, V., Cheek, L., & Ball, J. (2003). Statistics review 8: Qualitative data - tests of association. Critical Care, 8(1), 46. https://doi.org/10.1186/cc2428\n\n\nBrownlee, J. (2020a). Train-test split for evaluating machine learning algorithms. https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/\n\n\nBrownlee, J. (2020b). Why one-hot encode data in machine learning? https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n\n\nDavenport, T. H., & Patil, D. J. (2012). Data scientist: The sexiest job of the 21st century. Harvard Business Review. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century\n\n\nDavenport, T. H., & Patil, D. J. (2022). Is data scientist still the sexiest job of the 21st century? Harvard Business Review. https://hbr.org/2022/07/is-data-scientist-still-the-sexiest-job-of-the-21st-century\n\n\nDeori, T. (2023). Demystifying Machine Learning Challenges: Outliers. https://levelup.gitconnected.com/demystifying-machine-learning-challenges-outliers-34aa4f45a1b9\n\n\nEllis, C. (2022). Hyperparameter tuning in random forests. https://crunchingthedata.com/hyperparameter-tuning-in-random-forests/\n\n\nH2O.ai. (2024). Distributed random forest (DRF)  H2O 3.46.0.1 documentation. https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html\n\n\nJafari, M., & Ansari-Pour, N. (2019). Why, when and how to adjust your p values? Cell Journal (Yakhteh), 20(4), 604–607. https://doi.org/10.22074/cellj.2019.5992\n\n\nNeuhof, M. (2018). Chi-square (and post-hoc) tests in Python. https://neuhofmo.github.io/chi-square-and-post-hoc-in-python/\n\n\nRavi, R. (2022). One-Hot Encoding is making your Tree-Based Ensembles worse, here’s why? https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769\n\n\nRosidi, N. (2023). Navigating data science job titles: Data analyst vs. Data scientist vs. Data engineer. https://www.kdnuggets.com/navigating-data-science-job-titles-data-analyst-vs-data-scientist-vs-data-engineer\n\n\nSelvaraj, N. (2022). Unable to land a data science job? Here’s why. https://www.kdnuggets.com/unable-to-land-a-data-science-job-heres-why\n\n\nSimmons, L. (2023). How to become a data scientist. https://www.computerscience.org/careers/data-science/how-to-become/\n\n\nU.S. Bureau of Labor Statistics. (2024). Data Scientists : Occupational Outlook Handbook: : U.S. Bureau of Labor Statistics. https://www.bls.gov/ooh/math/data-scientists.htm\n\n\nVisualizing TensorFlow Decision Forest Trees with dtreeviz. (2024). https://www.tensorflow.org/decision_forests/tutorials/dtreeviz_colab\n\n\nZangari, M. (n.d.). Jobs and Salaries in Data field 2024."
  }
]